---
title: '**Lapse: Model tuning and selection**'
author: '*Roberto Jes√∫s Alcaraz Molina*'
date: "25/05/2021"
output:
  prettydoc::html_pretty:
    theme: cayman
    df_print: paged
header-includes: 
- \usepackage{float}
- \usepackage{amsbsy}
- \usepackage{amsmath}
- \usepackage{graphicx}
- \usepackage{subfig}
- \usepackage{booktabs}
---

```{r include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      echo = T, 
                      message = FALSE,
                      fig.pos="H", 
                      fig.align="center",
                      fig.width=15,
                      cache=FALSE, error = TRUE)
```

```{r, echo = F}
# install.packages("pacman")
# devtools::install_github("stevenpawley/recipeselectors")
pacman::p_load(tidyverse, tidymodels, workflowsets, tune, patchwork, dotwhisker, doParallel, mgcv, performance, recipeselectors, vip)
theme_set(theme_bw())

# Models packages
pacman::p_load(ranger)
```

```{r}
lapse_data <- readRDS("../00_data/insurance_lapse.RDS")
lapse_data$lapse <- as.factor(lapse_data$lapse)
lapse_data$capital <- as_double(lapse_data$capital)
lapse_data <- lapse_data %>%
  filter(actuarial_age >= 21, actuarial_age <= 61)

set.seed(123)

lapse_split <- initial_split(lapse_data, prop = 0.7, strata = lapse)
lapse_train <- training(lapse_split)
lapse_test  <- testing(lapse_split)

set.seed(23)
lapse_folds <- vfold_cv(lapse_train, v = 5, strata = lapse)
```

# Metrics
```{r}
grid_ctrl <- control_grid(
  save_pred = TRUE, 
  save_workflow = TRUE, 
  event_level = "second"
  )

my_metrics = metric_set(f_meas, kap, sensitivity, specificity)
```


# Models

```{r}
kknn_rec <- 
  recipe(formula = lapse ~ sex + duration + actuarial_age + BMI + 
    capital, data = lapse_train) %>%
  step_log(capital, BMI, base = 10) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors(), -all_nominal()) 

kknn_model <- 
  nearest_neighbor(neighbors = tune(), dist_power = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("kknn") 

kknn_wf <- 
  workflow() %>% 
  add_recipe(kknn_rec) %>% 
  add_model(kknn_model) 
```

```{r}
svm_rec <- 
  recipe(formula = lapse ~ sex + duration + actuarial_age + BMI + 
    capital, data = lapse_train) %>%
  step_log(capital, BMI, base = 10) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_corr(all_predictors())

svm_model <-
  svm_poly(cost = tune(), degree = tune(), scale_factor = tune()) %>%
  set_engine('kernlab') %>%
  set_mode('classification')

svm_wf <- 
  workflow() %>%
  add_recipe(svm_rec) %>%
  add_model(svm_model)
```


```{r}
# Decision Tree
dt_rec <- 
  recipe(formula = lapse ~ sex + duration + actuarial_age + BMI + 
     capital, data = lapse_train) %>%
  step_log(capital, BMI, base = 10) %>%
  step_dummy(all_nominal_predictors())

dt_model <- 
  decision_tree(cost_complexity = tune(), tree_depth = tune(), min_n = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("rpart")

dt_wf <- 
  workflow() %>%
  add_recipe(dt_rec) %>%
  add_model(dt_model)
```

```{r}
# Random Forest
rf_rec <- 
  recipe(formula = lapse ~ sex + duration + actuarial_age + BMI + 
    capital, data = lapse_train) %>%
  step_log(capital, BMI, base = 10) %>%
  step_dummy(all_nominal_predictors())

rf_model <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

rf_wf <- 
  workflow() %>%
  add_recipe(rf_rec) %>%
  add_model(rf_model)
```


```{r}
mlp_rec <- 
  recipe(formula = lapse ~ sex + duration + actuarial_age + BMI + 
    capital, data = lapse_train) %>%
  step_log(capital, BMI, base = 10) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_corr(all_predictors())

mlp_model <-
  mlp(hidden_units = tune(), epochs = tune(), penalty = tune()) %>%
  set_engine('nnet') %>%
  set_mode('classification')

mlp_wf <- 
  workflow() %>%
  add_recipe(mlp_rec) %>%
  add_model(mlp_model)
```


# Parameter tuning 

```{r, eval=F}
# KKNN
set.seed(123)
kknn_param <- kknn_wf %>% 
  parameters() %>% 
  update(
    neighbors = neighbors(c(1, 21))
  )
  
max_ent_kknn <- grid_max_entropy(kknn_param, size = 5)
max_ent_kknn$dist_power <- ifelse(max_ent_kknn$dist_power >= 1.5, 2, 1)

t <- Sys.time()
cl <- makePSOCKcluster(7)
registerDoParallel(cl)

kknn_wf_tune <- kknn_wf %>%
  tune_grid(
    resamples = lapse_folds,
    grid = max_ent_kknn,
    control = grid_ctrl,
    metrics = my_metrics
    )

stopCluster(cl)
saveRDS(kknn_wf_tune, "../02_lapse_model/results_lapse/kknn_wf_tune.RDS")
t1 <- Sys.time()
t1 - t

# SVM
set.seed(123)
max_ent_svm <- grid_max_entropy(parameters(svm_wf), size = 5)

t <- Sys.time()
cl <- makePSOCKcluster(7)
registerDoParallel(cl)

svm_wf_tune <- svm_wf %>%
  tune_grid(
    resamples = lapse_folds,
    grid = max_ent_svm,
    control = grid_ctrl,
    metrics = my_metrics
    )

stopCluster(cl)
saveRDS(svm_wf_tune, "../02_lapse_model/results_lapse/svm_wf_tune.RDS")
t2 <- Sys.time()
t2 - t

# Decision tree
set.seed(123)
max_ent_dt <- grid_max_entropy(parameters(dt_wf), size = 5)

t <- Sys.time()
cl <- makePSOCKcluster(7)
registerDoParallel(cl)

dt_wf_tune <- dt_wf %>%
  tune_grid(
    resamples = lapse_folds,
    grid = max_ent_dt,
    control = grid_ctrl,
    metrics = my_metrics
    )

saveRDS(dt_wf_tune, "../02_lapse_model/results_lapse/dt_wf_tune.RDS")
stopCluster(cl)

t3 <- Sys.time()
t3 - t

# Random Forest
set.seed(123)

rf_param <- rf_wf %>%
  parameters() %>%
  update(
    mtry = finalize(mtry(c(1, 10))),
    )

max_ent_rf <- grid_max_entropy(rf_param, size = 5)

t <- Sys.time()
cl <- makePSOCKcluster(7)
registerDoParallel(cl)

rf_wf_tune <- rf_wf %>%
  tune_grid(
    resamples = lapse_folds,
    grid = max_ent_rf,
    control = grid_ctrl,
    metrics = my_metrics
    )

saveRDS(rf_wf_tune, "../02_lapse_model/results_lapse/rf_wf_tune.RDS")
stopCluster(cl)

t4 <- Sys.time()
t4 - t

# MLP
set.seed(123)
max_ent_mlp <- grid_max_entropy(parameters(mlp_wf), size = 5)

t <- Sys.time()
cl <- makePSOCKcluster(7)
registerDoParallel(cl)

mlp_wf_tune <- mlp_wf %>%
  tune_grid(
    resamples = lapse_folds,
    grid = max_ent_mlp,
    control = grid_ctrl,
    metrics = my_metrics
    )

stopCluster(cl)
saveRDS(mlp_wf_tune, "../02_lapse_model/results_lapse/mlp_wf_tune.RDS")
t5 <- Sys.time()
t5 - t
```

```{r}
kknn_wf_tune <- readRDS("results_lapse/kknn_wf_tune.RDS")
dt_wf_tune <- readRDS("results_lapse/dt_wf_tune.RDS")
mlp_wf_tune <- readRDS("results_lapse/mlp_wf_tune.RDS") 
```

```{r}
wflow_set <- as_workflow_set(
  kknn = kknn_wf_tune, 
  #svm = svm_wf_tune,
  dt = dt_wf_tune,
  mlp = mlp_wf_tune
  )

wflow_set %>% collect_metrics() %>% 
  filter(.metric == "f_meas") %>% 
  arrange(desc(mean))

wflow_set %>% collect_metrics() %>% 
  filter(wflow_id == "kknn", .config == "Preprocessor1_Model2")
```


```{r}
# DT
dt_param <- dt_wf_tune %>%
  collect_metrics() %>%
  filter(.metric == "f_meas") %>%
  arrange(desc(mean)) %>%
  slice(1) %>%
  dplyr::select(cost_complexity, tree_depth, min_n)

dt_wf <- dt_wf %>%
  finalize_workflow(dt_param)

dt_final_wf <- dt_wf %>%
  fit(lapse_train_prep)

rpart.plot::rpart.plot(dt_final_wf$fit$fit$fit, roundint=FALSE)
dt_final_wf <- predict(dt_final_wf, lapse_train_prep)

dt_final_wf %>%
  bind_cols(lapse = lapse_train_prep$lapse) %>% 
  conf_mat(truth = lapse,
           estimate = .pred_class) %>%
  summary(event_level = "second")


kknn_param <- kknn_wf_tune %>%
  collect_metrics() %>%
  filter(.metric == "f_meas") %>%
  arrange(desc(mean)) %>%
  slice(1) %>%
  dplyr::select(neighbors, dist_power)

kknn_wf <- kknn_wf %>%
  finalize_workflow(kknn_param)

kknn_final_wf <- kknn_wf %>%
  last_fit(lapse_split)

kknn_final_wf %>%
  collect_predictions() %>%
  conf_mat(truth = lapse,
           estimate = .pred_class) 
```


