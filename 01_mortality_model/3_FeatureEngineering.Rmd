---
title: '**Mortality: Feature Engineering**'
author: '*Roberto Jesús Alcaraz Molina*'
date: "14/04/2021"
output:
  prettydoc::html_pretty:
    theme: cayman
    df_print: paged
header-includes: 
- \usepackage{float}
- \usepackage{amsbsy}
- \usepackage{amsmath}
- \usepackage{graphicx}
- \usepackage{subfig}
- \usepackage{booktabs}
---

```{r include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      echo = T, 
                      message = FALSE,
                      fig.pos="H", 
                      fig.align="center",
                      fig.width=10,
                      cache=FALSE, error = TRUE)
```

```{r, echo = F}
# install.packages("pacman")
# devtools::install_github("stevenpawley/recipeselectors")
pacman::p_load(tidyverse, tidymodels, workflowsets, tune, patchwork, dotwhisker, doParallel, mgcv, performance, recipeselectors, vip, ggfortify)
theme_set(theme_bw())

# Models packages
pacman::p_load(ranger)
```

# Code
```{r}
insurance <- readRDS("../00_data/insurance.RDS")


set.seed(123)

insurance_split <- initial_split(insurance, prop = 0.7, strata = mortality)
insurance_train <- training(insurance_split)
insurance_test  <- testing(insurance_split)
```


In this step of the project, we will analyze the following things:

  - Variable selection through gam, drop (p-value > 0.2) and random forest.
  - Interaction between variables.
  - Preprocessing steps taking into account the EDA.

# Variable selection

## Recursive feature selection with Random Forest


```{r}
rfe_model <- rand_forest() %>%
  set_engine("ranger", importance = "permutation") %>%
  set_mode("classification")

# Predictive model for the deaths
set.seed(1234)
select_rec <- 
  recipe(mortality ~ period + cover + sex + smoker + good_health +
                   actuarial_age + duration + capital + IMC,
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01) %>%
  step_select_vip(all_predictors(), outcome = "mortality", model = rfe_model, top_p = 7)

new_data <- select_rec %>% prep() %>% juice()
new_data

# The recursive feature selection with Random Forest discard the variables cover and good_health.
```



## GAM models

```{r}
gam_model <- gam(mortality ~ period + sex + smoker +
                   s(actuarial_age) + s(duration) + s(capital) + s(IMC),
                 data = insurance_train, family = "binomial")
summary(gam_model)

# Parametric coefficients:
#             Estimate Std. Error z value Pr(>|z|)    
# (Intercept)  -7.5754     0.1579 -47.972  < 2e-16 ***
# period2011   -0.1234     0.1730  -0.713  0.47579    
# period2012   -0.2812     0.1824  -1.541  0.12323    
# sexwoman     -0.5228     0.1903  -2.747  0.00602 ** 
# smokeryes     0.6366     0.1587   4.011 6.05e-05 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Approximate significance of smooth terms:
#                    edf Ref.df  Chi.sq p-value    
# s(actuarial_age) 1.029  1.057 114.620 < 2e-16 ***
# s(duration)      2.182  2.745   3.646 0.20969    
# s(capital)       3.159  3.762  13.768 0.00515 ** 
# s(IMC)           1.020  1.040   1.214 0.27912    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# R-sq.(adj) =  0.00102   Deviance explained = 6.44%
# UBRE = -0.98893  Scale est. = 1         n = 264473

gam_model <- gam(mortality ~ sex + smoker + IMC_factor_1 +
                   actuarial_age + s(capital),
                 data = insurance_train, family = "binomial")
summary(gam_model)

# Parametric coefficients:
#                   Estimate Std. Error z value Pr(>|z|)    
# (Intercept)      -11.64784    0.43637 -26.693  < 2e-16 ***
# sexwoman          -0.50458    0.18456  -2.734  0.00626 ** 
# smokeryes          0.64120    0.15578   4.116 3.85e-05 ***
# IMC_factor_1risk   0.28128    0.15610   1.802  0.07155 .  
# actuarial_age      0.09503    0.00874  10.873  < 2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Approximate significance of smooth terms:
#              edf Ref.df Chi.sq p-value   
# s(capital) 3.052  3.642  12.92 0.00689 **
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# R-sq.(adj) =  0.001   Deviance explained = 6.21%
# UBRE = -0.98894  Scale est. = 1         n = 264473
plot(gam_model)

prob <- predict(gam_model, newdata = insurance_train, type = "response")

prob <- as_tibble(prob) %>%
  mutate(mortality = insurance_train$mortality)

pred_curve <- prob %>%
  roc_curve(mortality, value, event_level = "second")

pred_curve %>%
  mutate(sum = specificity + sensitivity) %>%
  filter(sum == max(sum))

prob %>%
  mutate(pred_class = as.factor(ifelse(value > 0.0006790912,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class)

prob %>%
  roc_auc(mortality, value, event_level = "second")
autoplot(pred_curve)
```

# With interactions:
```{r}
gam_model <- gam(mortality ~ sex + smoker + IMC_factor_1 + actuarial_age +
                   s(capital) + sex:smoker + sex:IMC_factor_1 +
                   sex:actuarial_age + smoker:IMC_factor_1 +
                   smoker:actuarial_age + IMC_factor_1:actuarial_age,
                 data = insurance_train, family = "binomial")
summary(gam_model) # No significant interaction

prob <- predict(gam_model, newdata = insurance_train, type = "response")

prob <- as_tibble(prob) %>%
  mutate(mortality = insurance_train$mortality)

pred_curve <- prob %>%
  roc_curve(mortality, value, event_level = "second")

pred_curve %>%
  mutate(sum = specificity + sensitivity) %>%
  filter(sum == max(sum))

prob %>%
  mutate(pred_class = as.factor(ifelse(value > 0.0006344557,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class)

prob %>%
  roc_auc(mortality, value, event_level = "second")
autoplot(pred_curve)
```



```{r}
set.seed(23)
# Recipe
rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3)

rec %>% prep() %>% juice

# Model
glm_model <- logistic_reg() %>%
  set_engine("glm")

# Workflow
glm_wflow <- workflow() %>%
  add_model(glm_model) %>%
  add_recipe(rec)

glm_fit <- fit(glm_wflow, insurance_train)
tidy(glm_fit)
```


# Interaction terms

Now, our model is going to be formed by the variables sex, smoker, IMC_factor_1 and capital. Regarding the interactions, we can add interaction terms between two categorical variables, or between one categorical and one numerical.

```{r}
rec <- rec %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes + actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes + sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk)
```



# Preprocessing steps:

After seeing some description of the variables, their effect on the model and their interactions, the preprocessing steps we are going to follow are:

1. A method of resampling for the unbalanced class (e.g. `step_upsample(mortality)`).

2. Convert to dummy variables all categorical since it is usually useful for the majority of models.

(3. We will apply natural splines to the variable `capital`)

4. We will add the interactions between the final variables.

Also, for some models, it is mandatory to scale and center the variables, but for the moment, we are not going to do it.

```{r}
set.seed(23)
# Recipe
rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes +
                  actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes +
                  sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk)

rec %>% prep() %>% juice

# Model
glm_model <- logistic_reg() %>%
  set_engine("glm")

# Workflow
glm_wflow <- workflow() %>%
  add_model(glm_model) %>%
  add_recipe(rec)

glm_fit <- fit(glm_wflow, insurance_train)
tidy(glm_fit)
```


Prediction in the training set and roc curve:
```{r}
# pred <- predict(glm_fit, insurance_train)
prob <- predict(glm_fit, insurance_train, type = "prob")

prob <- prob %>%
  mutate(mortality = insurance_train$mortality)

pred_curve <- prob %>%
  roc_curve(mortality, .pred_yes, event_level = "second")

pred_curve %>%
  mutate(sum = specificity + sensitivity) %>%
  filter(sum == max(sum))

prob %>%
  mutate(pred_class = as.factor(ifelse(.pred_yes > 0.00866713,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class)

prob %>%
  roc_auc(mortality, .pred_no)
autoplot(pred_curve)
```
















