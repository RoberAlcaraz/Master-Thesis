---
title: '**Mortality: Feature Engineering**'
author: '*Roberto Jesús Alcaraz Molina*'
date: "14/04/2021"
output:
  prettydoc::html_pretty:
    theme: cayman
    df_print: paged
header-includes: 
- \usepackage{float}
- \usepackage{amsbsy}
- \usepackage{amsmath}
- \usepackage{graphicx}
- \usepackage{subfig}
- \usepackage{booktabs}
---

```{r include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      echo = T, 
                      message = FALSE,
                      fig.pos="H", 
                      fig.align="center",
                      fig.width=10,
                      cache=FALSE, error = TRUE)
```

```{r, echo = F}
# install.packages("pacman")
# devtools::install_github("stevenpawley/recipeselectors")
pacman::p_load(tidyverse, tidymodels, workflowsets, tune, patchwork, dotwhisker, doParallel, mgcv, performance, recipeselectors, vip, ggfortify)
theme_set(theme_bw())

# Models packages
pacman::p_load(ranger)
```

# Code
```{r}
insurance <- readRDS("../00_data/insurance.RDS")


set.seed(123)

insurance_split <- initial_split(insurance, prop = 0.7, strata = mortality)
insurance_train <- training(insurance_split)
insurance_test  <- testing(insurance_split)

insurance_train <- insurance_train %>%
  filter(actuarial_age >= 21, actuarial_age <= 61) %>%
  filter(duration <= 13)
```


In this step of the project, we will analyze the following things:

  - Variable selection through gam, drop (p-value > 0.2) and random forest.
  - Interaction between variables.
  - Preprocessing steps taking into account the EDA.

# Variable selection

## Recursive feature selection with Random Forest


```{r}
rfe_model <- rand_forest() %>%
  set_engine("ranger", importance = "permutation") %>%
  set_mode("classification")

# Predictive model for the deaths
set.seed(1234)
select_rec <- 
  recipe(mortality ~ cover + sex + smoker + good_health +
                   actuarial_age + duration + capital + IMC,
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01) %>%
  step_select_vip(all_predictors(), outcome = "mortality", model = rfe_model, top_p = 6)

new_data <- select_rec %>% prep() %>% juice()
new_data

# The recursive feature selection with Random Forest discard the variables cover and good_health.
```



## GAM models

```{r, eval = F}
insurance_train_prep <- 
  recipe(mortality ~ sex + smoker +
                   actuarial_age + duration + capital + IMC,
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  prep() %>% juice()

# Here we test if they are non-linear or not
gam_model <- gam(mortality ~ sex + smoker +
                   s(actuarial_age, bs = "ps") + s(duration, bs = "ps") +
                   s(capital, bs = "ps") + s(IMC, bs = "ps"),
                 data = insurance_train_prep, family = "binomial", method = "REML", select = F)
summary(gam_model)

# Parametric coefficients:
#             Estimate Std. Error z value Pr(>|z|)    
# (Intercept) -5.02743    0.03668 -137.06   <2e-16 ***
# sexwoman    -0.59497    0.05519  -10.78   <2e-16 ***
# smokeryes    0.60302    0.04389   13.74   <2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Approximate significance of smooth terms:
#                    edf Ref.df  Chi.sq p-value    
# s(actuarial_age) 7.075  7.713 1726.72 < 2e-16 ***
# s(duration)      8.158  8.614  110.88 < 2e-16 ***
# s(capital)       4.029  4.320  121.62 < 2e-16 ***
# s(IMC)           4.097  4.682   21.78 0.00143 ** 
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# R-sq.(adj) =  0.0156   Deviance explained = 9.81%
# -REML =  13114  Scale est. = 1         n = 260597

# And here, if they should be in the model
gam_model2 <- gam(mortality ~ sex + smoker +
                   s(actuarial_age, bs = "ps") + s(duration, bs = "ps") +
                   s(capital, bs = "ps") + s(IMC, bs = "ps"),
                 data = insurance_train_prep, family = "binomial", method = "REML", select = T)
summary(gam_model2)

# Parametric coefficients:
#             Estimate Std. Error z value Pr(>|z|)    
# (Intercept) -5.03351    0.03661 -137.48   <2e-16 ***
# sexwoman    -0.59054    0.05324  -11.09   <2e-16 ***
# smokeryes    0.60497    0.04388   13.79   <2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Approximate significance of smooth terms:
#                    edf Ref.df  Chi.sq  p-value    
# s(actuarial_age) 7.176      9 1728.36  < 2e-16 ***
# s(duration)      8.052      9  105.19  < 2e-16 ***
# s(capital)       4.086      8  122.91  < 2e-16 ***
# s(IMC)           1.249      9   10.58 0.000872 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# R-sq.(adj) =  0.0156   Deviance explained = 9.77%
# -REML =  13130  Scale est. = 1         n = 260597

plot(gam_model2, ylim = c(-10, 10))
```


```{r}
prob <- predict(gam_model2, newdata = insurance_train_prep, type = "response")

prob <- as_tibble(prob) %>%
  mutate(mortality = insurance_train_prep$mortality)

prec_rec_curve <- prob %>%
  pr_curve(mortality, value, event_level = "second")

thres <- prec_rec_curve %>%
  mutate(sum = (5)*(recall * precision)/((4*precision) + recall)) %>%
  filter(sum == max(sum, na.rm = T)) %>%
  select(.threshold) %>%
  pull()

# 0.03055535
confusion_matrix <- prob %>%
  mutate(pred_class = as.factor(ifelse(value > thres,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class)

confusion_matrix %>%
  summary(event_level = "second", beta = 2)
```

# With interactions:

```{r}
t1 <- insurance_train %>%
  group_by(actuarial_age) %>%
  mutate(
    mortality_man = sum(mortality == "yes" & sex == "man"),
    mortality_woman = sum(mortality == "yes" & sex == "woman"),
    ) %>%
  select(actuarial_age, mortality_man, mortality_woman) %>%
  distinct() %>%
  arrange(actuarial_age)

t_man <- insurance_train %>%
  group_by(actuarial_age) %>%
  filter(sex == "man") %>%
  mutate(exp_man = sum(exp)) %>%
  select(actuarial_age, exp_man) %>%
  distinct() %>%
  arrange(actuarial_age)

t_woman <- insurance_train %>%
  group_by(actuarial_age) %>%
  filter(sex == "woman") %>%
  mutate(exp_woman = sum(exp)) %>%
  select(actuarial_age, exp_woman) %>%
  distinct() %>%
  arrange(actuarial_age)

t <- t1 %>%
  bind_cols(
    exp_man = t_man$exp_man,
    .name_repair = "unique"
    ) %>%
  bind_cols(
    exp_woman = t_woman$exp_woman,
    .name_repair = "unique"
  ) %>%
  mutate(
    `mortality_man/exp` = mortality_man/exp_man,
    `mortality_woman/exp` = mortality_woman/exp_woman
    )

t <- t %>%
  pivot_longer(cols = c(`mortality_man/exp`, `mortality_woman/exp`), names_to = "values")

t %>%
  ggplot() +
  geom_point(aes(actuarial_age, value, color = values, fill = values), alpha = 0.4)
```

```{r}
gam_model <- gam(mortality ~ sex + smoker +
                   s(actuarial_age, bs = "ps") + s(duration, bs = "ps") +
                   s(capital, bs = "ps") + s(IMC, bs = "ps") +
                   s(actuarial_age, bs = "ps", by = sex) +
                   s(actuarial_age, bs = "ps", by = smoker) + 
                   s(duration, bs = "ps", by = sex) +
                   s(duration, bs = "ps", by = smoker) +
                   s(capital, bs = "ps", by = sex) +
                   s(capital, bs = "ps", by = smoker) +
                   s(IMC, bs = "ps", by = sex) +
                   s(IMC, bs = "ps", by = smoker),
                 data = insurance_train_prep, family = "binomial", method = "REML", select = F)

summary(gam_model)

# Parametric coefficients:
#                    Estimate Std. Error z value Pr(>|z|)    
# (Intercept)        -5.32871    0.05755 -92.597  < 2e-16 ***
# sexwoman           -0.83848    0.15147  -5.536 3.10e-08 ***
# smokeryes           0.54040    0.10100   5.350 8.78e-08 ***
# sexwoman:smokeryes  0.03907    0.13408   0.291    0.771    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Approximate significance of smooth terms:
#                                 edf  Ref.df Chi.sq  p-value    
# s(actuarial_age):sexman    8.367434 8.65932 57.424 7.59e-06 ***
# s(actuarial_age):sexwoman  1.960535 2.19488  0.487 0.892876    
# s(actuarial_age):smokerno  5.080668 5.51675 15.760 0.009526 ** 
# s(actuarial_age):smokeryes 7.600967 7.85593 58.552  < 2e-16 ***
# s(duration):sexman         1.041007 1.04917  0.522 0.467231    
# s(duration):sexwoman       4.014722 4.82937 41.420  < 2e-16 ***
# s(duration):smokerno       8.343377 8.70977 74.225  < 2e-16 ***
# s(duration):smokeryes      8.347030 8.79948 95.777  < 2e-16 ***
# s(capital):sexman          4.204065 4.51214 59.041  < 2e-16 ***
# s(capital):sexwoman        0.001226 0.00213  0.000 0.995554    
# s(capital):smokerno        2.224963 2.56282 31.501 0.000256 ***
# s(capital):smokeryes       1.000525 1.00103 38.993  < 2e-16 ***
# s(IMC):sexman              1.001356 1.00270  1.107 0.293718    
# s(IMC):sexwoman            3.168609 3.60054 38.616 1.79e-05 ***
# s(IMC):smokerno            1.001290 1.00257  1.092 0.296341    
# s(IMC):smokeryes           2.827572 3.20640 30.024 2.49e-06 ***
```

```{r}
prob <- predict(gam_model, newdata = insurance_train_prep, type = "response")

prob <- as_tibble(prob) %>%
  mutate(mortality = insurance_train_prep$mortality)

prec_rec_curve <- prob %>%
  pr_curve(mortality, value, event_level = "second")

thres <- prec_rec_curve %>%
  mutate(sum = (5)*(recall * precision)/((4*precision) + recall)) %>%
  filter(sum == max(sum, na.rm = T)) %>%
  select(.threshold) %>%
  pull()


confusion_matrix <- prob %>%
  mutate(pred_class = as.factor(ifelse(value > thres,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class)

confusion_matrix %>%
  summary(event_level = "second", beta = 2)
```




```{r}
set.seed(23)
# Recipe
rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3)

rec %>% prep() %>% juice

# Model
glm_model <- logistic_reg() %>%
  set_engine("glm")

# Workflow
glm_wflow <- workflow() %>%
  add_model(glm_model) %>%
  add_recipe(rec)

glm_fit <- fit(glm_wflow, insurance_train)
tidy(glm_fit)
```


# Interaction terms


# Preprocessing steps:

After seeing some description of the variables, their effect on the model and their interactions, the preprocessing steps we are going to follow are:

1. A method of resampling for the unbalanced class (e.g. `step_upsample(mortality)`).

2. Convert to dummy variables all categorical since it is usually useful for the majority of models.

3. We will add the interactions between the final variables.

Also, for some models, it is mandatory to scale and center the variables, but for the moment, we are not going to do it.



