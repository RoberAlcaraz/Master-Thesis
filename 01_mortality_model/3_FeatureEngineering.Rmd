---
title: '**Mortality: Feature Engineering**'
author: '*Roberto Jesús Alcaraz Molina*'
date: "14/04/2021"
output:
  prettydoc::html_pretty:
    theme: cayman
    df_print: paged
header-includes: 
- \usepackage{float}
- \usepackage{amsbsy}
- \usepackage{amsmath}
- \usepackage{graphicx}
- \usepackage{subfig}
- \usepackage{booktabs}
---

```{r include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      echo = T, 
                      message = FALSE,
                      fig.pos="H", 
                      fig.align="center",
                      fig.width=10,
                      cache=FALSE, error = TRUE)
```

```{r, echo = F}
# install.packages("pacman")
# devtools::install_github("stevenpawley/recipeselectors")
pacman::p_load(tidyverse, tidymodels, workflowsets, tune, patchwork, dotwhisker, doParallel, mgcv, performance, recipeselectors, vip, ggfortify)
theme_set(theme_bw())

# Models packages
pacman::p_load(ranger)
```

# Code
```{r}
insurance <- readRDS("../00_data/insurance.RDS")


set.seed(123)

insurance_split <- initial_split(insurance, prop = 0.7, strata = mortality)
insurance_train <- training(insurance_split)
insurance_test  <- testing(insurance_split)
```


In this step of the project, we will analyze the following things:

  - Variable selection through gam, drop (p-value > 0.2) and random forest.
  - Interaction between variables.
  - Preprocessing steps taking into account the EDA.

# Variable selection

## Recursive feature selection with Random Forest


```{r}
rfe_model <- rand_forest() %>%
  set_engine("ranger", importance = "permutation") %>%
  set_mode("classification")

# Predictive model for the deaths
set.seed(1234)
select_rec <- 
  recipe(mortality ~ period + cover + sex + smoker + good_health +
                   actuarial_age + duration + capital + IMC,
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01) %>%
  step_select_vip(all_predictors(), outcome = "mortality", model = rfe_model, top_p = 7)

new_data <- select_rec %>% prep() %>% juice()
new_data

# The recursive feature selection with Random Forest discard the variables cover and good_health.
```



## GAM models

```{r}
insurance_train_prep <- 
  recipe(mortality ~ period + sex + smoker +
                   actuarial_age + duration + capital + IMC,
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  prep() %>% juice()

gam_model <- gam(mortality ~ period + sex + smoker +
                   s(actuarial_age, bs = "ps") + s(duration, bs = "ps") +
                   s(capital, bs = "ps") + s(IMC, bs = "ps"),
                 data = insurance_train_prep, family = "binomial", method = "REML", select = F)
summary(gam_model)

# Parametric coefficients:
#             Estimate Std. Error  z value Pr(>|z|)    
# (Intercept) -5.00627    0.04556 -109.876  < 2e-16 ***
# period2011  -0.15581    0.04709   -3.309 0.000937 ***
# period2012  -0.23556    0.04925   -4.783 1.73e-06 ***
# sexwoman    -0.54077    0.05442   -9.936  < 2e-16 ***
# smokeryes    0.70401    0.04278   16.457  < 2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Approximate significance of smooth terms:
#                    edf Ref.df  Chi.sq  p-value    
# s(actuarial_age) 6.620      9 1789.60  < 2e-16 ***
# s(duration)      7.741      9  108.65  < 2e-16 ***
# s(capital)       4.858      9  164.00  < 2e-16 ***
# s(IMC)           3.472      9   31.66 4.31e-07 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#
# R-sq.(adj) =  0.0195   Deviance explained = 10.6%
# -REML =  13334  Scale est. = 1         n = 266927

gam_model <- gam(mortality ~ period + sex + smoker +
                   s(actuarial_age, bs = "ps") + s(duration, bs = "ps") +
                   s(capital, bs = "ps") + s(IMC, bs = "ps"),
                 data = insurance_train_prep, family = "binomial", method = "REML", select = F)
summary(gam_model)

# Parametric coefficients:
#             Estimate Std. Error  z value Pr(>|z|)    
# (Intercept) -5.01508    0.04579 -109.521  < 2e-16 ***
# period2011  -0.15452    0.04709   -3.281  0.00103 ** 
# period2012  -0.23469    0.04924   -4.766 1.88e-06 ***
# sexwoman    -0.54183    0.05450   -9.942  < 2e-16 ***
# smokeryes    0.70454    0.04278   16.468  < 2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Approximate significance of smooth terms:
#                    edf Ref.df  Chi.sq  p-value    
# s(actuarial_age) 6.725  6.999 1793.16  < 2e-16 ***
# s(duration)      7.694  7.961   98.69  < 2e-16 ***
# s(capital)       4.436  4.746  146.86  < 2e-16 ***
# s(IMC)           4.303  4.828   34.27 6.32e-06 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# R-sq.(adj) =  0.0197   Deviance explained = 10.7%
# -REML =  13310  Scale est. = 1         n = 266927

plot(gam_model, residuals = T, scheme = 1, col = "red")

prob <- predict(gam_model, newdata = insurance_train_prep, type = "response")

prob <- as_tibble(prob) %>%
  mutate(mortality = insurance_train_prep$mortality)

pred_curve <- prob %>%
  roc_curve(mortality, value, event_level = "second")

prec_rec_curve <- prob %>%
  pr_curve(mortality, value, event_level = "second")

autoplot(prec_rec_curve)

thres <- pred_curve %>%
  mutate(sum = specificity + sensitivity) %>%
  filter(sum == max(sum)) %>%
  select(.threshold) %>%
  pull()

thres <- prec_rec_curve %>%
  mutate(sum = (5)*(recall * precision)/((4*precision) + recall)) %>%
  filter(sum == max(sum, na.rm = T)) %>%
  select(.threshold) %>%
  pull()

# thres <- 0.0006790912
confusion_matrix <- prob %>%
  mutate(pred_class = as.factor(ifelse(value > thres,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class)
confusion_matrix %>%
  summary(event_level = "second", beta = 2)

prob %>%
  roc_auc(mortality, value, event_level = "second")
autoplot(pred_curve)
```

```{r}
t <- pred_curve %>%
  select(.threshold) %>%
  pull

t <- t[-1]
t <- t[-90748]

t <- quantile(t, probs = seq(0, 0.8, 0.001))
f_metric <- seq(1, length(t))
length(f_metric)
  
for (i in 1:length(t)){
  f_metric[i] <- prob %>%
    mutate(pred_class = as.factor(ifelse(value > t[i], "yes", "no"))) %>%
    f_meas(mortality, pred_class, beta = 2, event_level = "second") %>% select(.estimate) %>% pull()
}

df <- as_tibble(cbind(t, f_metric))
df %>%
  filter(f_metric == max(f_metric))

prob %>%
  mutate(pred_class = as.factor(ifelse(value > 0.0006758093,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class) %>%
  summary(beta = 2, event_level = "second")

t <- pred_curve %>%
  select(.threshold) %>%
  pull

length(which(t < 0.0006758093))
t <- t[58000:59000]

f_metric <- seq(1, length(t))
length(f_metric)
  
for (i in 1:length(t)){
  f_metric[i] <- prob %>%
    mutate(pred_class = as.factor(ifelse(value > t[i], "yes", "no"))) %>%
    f_meas(mortality, pred_class, beta = 2, event_level = "second") %>% select(.estimate) %>% pull()
}

df <- as_tibble(cbind(t, f_metric))
df %>%
  filter(f_metric == max(f_metric))

prob %>%
  mutate(pred_class = as.factor(ifelse(value > 0.0006790775,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class) %>%
  summary(beta = 2, event_level = "second")
```

# With interactions:
```{r}
gam_model <- gam(mortality ~ sex + smoker + IMC_factor_1 + actuarial_age +
                   s(capital) + sex:smoker + sex:IMC_factor_1 +
                   sex:actuarial_age + smoker:IMC_factor_1 +
                   smoker:actuarial_age + IMC_factor_1:actuarial_age,
                 data = insurance_train, family = "binomial")
summary(gam_model) # No significant interaction

prob <- predict(gam_model, newdata = insurance_train, type = "response")

prob <- as_tibble(prob) %>%
  mutate(mortality = insurance_train$mortality)

pred_curve <- prob %>%
  roc_curve(mortality, value, event_level = "second")

pred_curve %>%
  mutate(sum = specificity + sensitivity) %>%
  filter(sum == max(sum))

prob %>%
  mutate(pred_class = as.factor(ifelse(value > 0.0006344557,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class)

prob %>%
  roc_auc(mortality, value, event_level = "second")
autoplot(pred_curve)
```



```{r}
set.seed(23)
# Recipe
rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3)

rec %>% prep() %>% juice

# Model
glm_model <- logistic_reg() %>%
  set_engine("glm")

# Workflow
glm_wflow <- workflow() %>%
  add_model(glm_model) %>%
  add_recipe(rec)

glm_fit <- fit(glm_wflow, insurance_train)
tidy(glm_fit)
```


# Interaction terms

Now, our model is going to be formed by the variables sex, smoker, IMC_factor_1 and capital. Regarding the interactions, we can add interaction terms between two categorical variables, or between one categorical and one numerical.

```{r}
rec <- rec %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes + actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes + sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk)
```



# Preprocessing steps:

After seeing some description of the variables, their effect on the model and their interactions, the preprocessing steps we are going to follow are:

1. A method of resampling for the unbalanced class (e.g. `step_upsample(mortality)`).

2. Convert to dummy variables all categorical since it is usually useful for the majority of models.

(3. We will apply natural splines to the variable `capital`)

4. We will add the interactions between the final variables.

Also, for some models, it is mandatory to scale and center the variables, but for the moment, we are not going to do it.

```{r}
set.seed(23)
# Recipe
rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes +
                  actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes +
                  sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk)

rec %>% prep() %>% juice

# Model
glm_model <- logistic_reg() %>%
  set_engine("glm")

# Workflow
glm_wflow <- workflow() %>%
  add_model(glm_model) %>%
  add_recipe(rec)

glm_fit <- fit(glm_wflow, insurance_train)
tidy(glm_fit)
```


Prediction in the training set and roc curve:
```{r}
# pred <- predict(glm_fit, insurance_train)
prob <- predict(glm_fit, insurance_train, type = "prob")

prob <- prob %>%
  mutate(mortality = insurance_train$mortality)

pred_curve <- prob %>%
  roc_curve(mortality, .pred_yes, event_level = "second")

pred_curve %>%
  mutate(sum = specificity + sensitivity) %>%
  filter(sum == max(sum))

prob %>%
  mutate(pred_class = as.factor(ifelse(.pred_yes > 0.00866713,
                                       "yes", "no"))) %>%
  conf_mat(truth = mortality,
           estimate = pred_class)

prob %>%
  roc_auc(mortality, .pred_no)
autoplot(pred_curve)
```
















