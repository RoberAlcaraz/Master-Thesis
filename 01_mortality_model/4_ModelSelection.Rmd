---
title: '**Mortality: Model tuning and selection**'
author: '*Roberto Jes√∫s Alcaraz Molina*'
date: "14/04/2021"
output:
  html_document:
    toc: T
    fig_caption: yes
header-includes: 
- \usepackage{float}
- \usepackage{amsbsy}
- \usepackage{amsmath}
- \usepackage{graphicx}
- \usepackage{subfig}
- \usepackage{booktabs}
---

```{r include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      echo = F, 
                      message = FALSE,
                      fig.pos="H", 
                      fig.align="center",
                      fig.width=15,
                      cache=FALSE, error = TRUE)
```

```{r, echo = F}
# install.packages("pacman")
pacman::p_load(tidyverse, tidymodels, workflowsets, tune, patchwork, FactoMineR, doParallel, usemodels)
theme_set(theme_bw())

# Models packages
pacman::p_load(ranger, baguette)
```

## Code

```{r, eval = T}
insurance <- readRDS("../00_data/insurance.RDS")

set.seed(123)

insurance_split <- initial_split(insurance, prop = 0.7, strata = mortality)
insurance_train <- training(insurance_split)
insurance_test  <- testing(insurance_split)

set.seed(23)
insurance_folds <- vfold_cv(insurance_train, v = 3, 
                            strata = mortality)

basic_rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes +
                  actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes +
                  sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk)
```

We are going to compare the following models: gam, pls, random forest and neural networks.

```{r}
grid_ctrl <- control_grid(
  save_pred = TRUE, 
  save_workflow = TRUE
  )

my_metrics = metric_set(recall, kap, )
```

```{r}
# GLM
glm_rec <- basic_rec

glm_model <-
  logistic_reg() %>%
  set_engine('glm')
```

```{r}
# PLS
pls_rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes +
                  actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes +
                  sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk) %>%
  step_zv(all_predictors())
  
pls_model <-
  plsmod::pls(predictor_prop = tune(), num_comp = tune()) %>%
  set_engine('mixOmics') %>%
  set_mode('classification')
```

```{r}
# Random Forest
rf_rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex + actuarial_age:smoker +
                  actuarial_age:IMC_factor_1 + sex:smoker +
                  sex:IMC_factor_1 + smoker:IMC_factor_1)

rf_rec %>% prep() %>% juice

ranger_spec <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")
```


```{r}
mlp_rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes +
                  actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes +
                  sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk) %>%
  step_zv(all_predictors()) %>%
  step_corr(all_predictors())

mlp_rec %>% prep() %>% juice

mlp_model <-
  mlp(hidden_units = tune(), penalty = tune(), dropout = tune(), epochs = tune(), activation = tune()) %>%
  set_engine('keras') %>%
  set_mode('classification')
```



```{r}
wflow <- workflow_set(
  preproc = list(
    log_reg = glm_rec,
    pls = pls_rec,
    random = rf_rec,
    neural_network = mlp_rec
  ),
  models = list(
    glm_wf = glm_model,
    wf = pls_model,
    forest_wf = rfe_model,
    mlp_wf = mlp_model
  ),
  cross = F
)
```

```{r}
cl <- makePSOCKcluster(8)
registerDoParallel(cl)

wflow_results <- wflow %>%
  workflow_map(
    seed = 1503,
    resamples = insurance_folds,
    grid = 10,
    metrics = metric_set(miss_rate_vec),
    control = grid_ctrl,
    verbose = T
   )

stopCluster(cl)
```

```{r}
# Results
cost_matrix <- tribble(
    ~truth,   ~estimate, ~cost,
    "yes", "no",  2,
    "no", "yes",  1
  )

wflow_results %>%
  pull_workflow_set_result("log_reg_glm_wf") %>%
  collect_metrics()

wflow_results %>%
  pull_workflow_set_result("log_reg_glmnet_wf") %>%
  collect_predictions() %>%
  group_by(id) %>%
  classification_cost(mortality, .pred_yes, costs = cost_matrix)

wflow_results %>%
  pull_workflow_set_result("dec_tree_rpart_wf") %>%
  collect_predictions() %>%
  group_by(id) %>%
  classification_cost(mortality, .pred_yes, costs = cost_matrix)

```





```{r, eval=F}
cl <- makePSOCKcluster(8)
registerDoParallel(cl)

# fit here

stopCluster(cl)
```


```{r, eval = F}
cl <- makePSOCKcluster(6)
registerDoParallel(cl)

glm_models <- 
  glm_models %>% 
  workflow_map("fit_resamples", 
               # Options to `workflow_map()`: 
               seed = 23, verbose = TRUE,
               # Options to `fit_resamples()`: 
               resamples = insurance_folds, control = keep_pred,
               metrics = metric_set(roc_auc, kap))

stopCluster(cl)

```


# Machine learning




Let's try different models

```{r}
kknn_recipe <- 
  recipe(formula = mortality ~ period + sex + smoker + actuarial_age + duration + capital + IMC, 
         data = insurance_train) %>% 
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 1234) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors()) 

kknn_spec <- 
  nearest_neighbor(neighbors = tune(), weight_func = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("kknn") 

kknn_workflow <- 
  workflow() %>% 
  add_recipe(kknn_recipe) %>% 
  add_model(kknn_spec) 


cl <- makePSOCKcluster(8)
registerDoParallel(cl)

set.seed(35790)
kknn_tune <- kknn_workflow %>%
  tune_grid(
    resamples = insurance_folds, 
    grid = 10
    )

stopCluster(cl)
```












