---
title: '**Mortality: Model tuning and selection**'
author: '*Roberto Jes√∫s Alcaraz Molina*'
date: "14/04/2021"
output:
  html_document:
    toc: T
    fig_caption: yes
header-includes: 
- \usepackage{float}
- \usepackage{amsbsy}
- \usepackage{amsmath}
- \usepackage{graphicx}
- \usepackage{subfig}
- \usepackage{booktabs}
---

```{r include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      echo = F, 
                      message = FALSE,
                      fig.pos="H", 
                      fig.align="center",
                      fig.width=15,
                      cache=FALSE, error = TRUE)
```

```{r, echo = F}
# install.packages("pacman")
pacman::p_load(tidyverse, tidymodels, workflowsets, tune, patchwork, FactoMineR, doParallel, usemodels, mgcv)
theme_set(theme_bw())

# Models packages
pacman::p_load(ranger, keras, tensorflow)
```

## Code

```{r, eval = T}
insurance <- readRDS("../00_data/insurance.RDS")

set.seed(123)

insurance_split <- initial_split(insurance, prop = 0.7, strata = mortality)
insurance_train <- training(insurance_split)
insurance_test  <- testing(insurance_split)

set.seed(23)
insurance_folds <- vfold_cv(insurance_train, v = 5, 
                            strata = mortality)

basic_rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes +
                  actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes +
                  sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk)
```

We are going to compare the following models: gam, pls, random forest and neural networks.

```{r}
grid_ctrl <- control_grid(
  save_pred = TRUE, 
  save_workflow = TRUE, 
  event_level = "second"
  )

f_meas_2 <- function(data, truth, estimate, na_rm = TRUE, ...){
  f_meas(
    data = data,
    truth = !! rlang::enquo(truth),
    estimate = !! rlang::enquo(estimate),
    # set beta = 2
    beta = 2,
    na_rm = TRUE,
    ...
  )
}

f_meas_2 <- new_class_metric(f_meas_2, direction = "maximize")

# It works
# prob %>%
#     mutate(pred_class = as.factor(ifelse(value > t[i], "yes", "no"))) %>%
#     f_meas(mortality, pred_class, beta = 2, event_level = "second")
# prob %>%
#     mutate(pred_class = as.factor(ifelse(value > t[i], "yes", "no"))) %>%
#     f_meas_2(mortality, pred_class)

my_metrics = metric_set(f_meas_2, recall, kap)
```


```{r}
# PLS
pls_rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes +
                  actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes +
                  sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk) %>%
  step_zv(all_predictors())
  
pls_model <-
  plsmod::pls(predictor_prop = tune(), num_comp = tune()) %>%
  set_engine('mixOmics') %>%
  set_mode('classification')

pls_wf <- 
  workflow() %>%
  add_recipe(pls_rec) %>%
  add_model(pls_model)
```

```{r}
# Random Forest
rf_rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_upsample(mortality, over_ratio = 0.01, seed = 123) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex + actuarial_age:smoker +
                  actuarial_age:IMC_factor_1 + sex:smoker +
                  sex:IMC_factor_1 + smoker:IMC_factor_1)


rf_model <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

rf_wf <- 
  workflow() %>%
  add_recipe(rf_rec) %>%
  add_model(rf_model)
```


```{r}
mlp_rec <- 
  recipe(mortality ~ sex + smoker + actuarial_age + IMC_factor_1 + capital, 
         data = insurance_train) %>%
  themis::step_downsample(mortality, seed = 123) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_bs(capital, deg_free = 3) %>%
  step_interact(terms = ~ actuarial_age:sex_woman + actuarial_age:smoker_yes +
                  actuarial_age:IMC_factor_1_risk + sex_woman:smoker_yes +
                  sex_woman:IMC_factor_1_risk + smoker_yes:IMC_factor_1_risk) %>%
  step_zv(all_predictors()) %>%
  step_corr(all_predictors())

mlp_model <-
  mlp(hidden_units = tune(), epochs = tune(), activation = tune()) %>%
  set_engine('keras') %>%
  set_mode('classification')

mlp_wf <- 
  workflow() %>%
  add_recipe(mlp_rec) %>%
  add_model(mlp_model)
```



```{r}
# GAM
n <- nrow(insurance_folds)

f2 <- seq(1, n)
kappa <- seq(1, n)
rec <- seq(1, n)

for (i in 1:n){
  analysis_data <- analysis(insurance_folds$splits[[i]])
  validation_data <- assessment(insurance_folds$splits[[i]])
  
  gam_model <- gam(mortality ~ sex + smoker + IMC_factor_1 +
                     actuarial_age + s(capital),
                   data = analysis_data, family = "binomial")
  
  prob <- predict(gam_model, newdata = validation_data, type = "response")

  prob <- as_tibble(prob) %>%
    mutate(mortality = validation_data$mortality)
  
  confusion_matrix <- prob %>%
    mutate(pred_class = as.factor(ifelse(value > 0.0006790775, "yes", "no"))) %>%
    conf_mat(truth = mortality, estimate = pred_class)
  
  f2[i] <- confusion_matrix %>% summary(event_level = "second", beta = 2) %>%
    filter(.metric == "f_meas") %>% select(.estimate) %>% pull()
  kappa[i] <- confusion_matrix %>% summary(event_level = "second") %>%
    filter(.metric == "kap") %>% select(.estimate) %>% pull()
  rec[i] <- confusion_matrix %>% summary(event_level = "second") %>%
    filter(.metric == "recall") %>% select(.estimate) %>% pull()
}

mean(f2)
mean(kappa)
mean(rec)
```

```{r}
# PLS
set.seed(123)
max_ent_pls <- grid_max_entropy(parameters(pls_wf), size = 5)

cl <- makePSOCKcluster(6)
registerDoParallel(cl)

pls_wf_tune <- pls_wf %>%
  tune_grid(
    resamples = insurance_folds,
    grid = max_ent_pls,
    control = grid_ctrl,
    metrics = my_metrics
    )

stopCluster(cl)
```


```{r}
# Random Forest
set.seed(123)

rf_param <- rf_wf %>%
  parameters() %>%
  update(mtry = finalize(mtry(c(1, 14))))

max_ent_rf <- grid_max_entropy(rf_param, size = 5)

cl <- makePSOCKcluster(8)
registerDoParallel(cl)

rf_wf_tune <- rf_wf %>%
  tune_grid(
    resamples = insurance_folds,
    grid = max_ent_rf,
    control = grid_ctrl,
    metrics = my_metrics,
    verbose = T
    )

stopCluster(cl)
```

```{r}
set.seed(123)
max_ent_mlp <- grid_max_entropy(parameters(mlp_wf), size = 5)

cl <- makePSOCKcluster(8)
registerDoParallel(cl)

mlp_wf_tune <- mlp_wf %>%
  tune_grid(
    resamples = insurance_folds,
    grid = max_ent_mlp,
    control = grid_ctrl,
    metrics = my_metrics,
    verbose = T
    )

stopCluster(cl)

mlp_param <- mlp_wf_tune %>%
  collect_metrics() %>%
  filter(.metric == "f_meas") %>%
  arrange(desc(mean)) %>%
  slice(1) %>%
  select(hidden_units, epochs, activation)

mlp_param <- tibble(
  hidden_units = 9,
  epochs = 210,
  activation = "linear"
)

autoplot(mlp_wf_tune)
```

```{r}
mlp_wf <- mlp_wf %>%
  finalize_workflow(mlp_param)

final_wf <- mlp_wf %>%
  last_fit(insurance_split)

final_wf %>%
  collect_predictions() %>%
  conf_mat(truth = mortality,
           estimate = .pred_class) %>%
  summary(event_level = "second", beta = 2)
```




```{r, eval=F}
cl <- makePSOCKcluster(8)
registerDoParallel(cl)

# fit here

stopCluster(cl)
```

